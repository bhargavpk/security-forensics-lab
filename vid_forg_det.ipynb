{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from scipy import ndimage\n",
    "import math"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def highPassFilter(img):\n",
    "    filteredImg = np.zeros(img.shape)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            prev_val = img[i][j-1] if j > 0 else 0\n",
    "            next_val = img[i][j+1] if j < img.shape[1]-1 else 0\n",
    "            next_next_val = img[i][j+2] if j < img.shape[1]-2 else 0 \n",
    "            filteredImg[i][j] = prev_val - 3*img[i][j] + 3*next_val - next_next_val\n",
    "    return filteredImg\n",
    "\n",
    "def gaussianHighPass(img):\n",
    "    low_pass = ndimage.gaussian_filter(img, sigma=3)\n",
    "    high_pass = img - low_pass\n",
    "    return high_pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def quantize(img, q, t):\n",
    "    rounded_img = np.array([[int(element)//q for element in row] for row in img]).astype('uint8')\n",
    "    truncated_img = np.array([[min(t, max(-t, element)) for element in row] for row in rounded_img]).astype('uint8')\n",
    "    return truncated_img"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Read video into a VideoCapture object\n",
    "vc = cv.VideoCapture('videos/video_pro2.avi')\n",
    "# Read tampered video\n",
    "vc_tamp = cv.VideoCapture('videos/v_out_4-2-2015-23-58-0.avi')\n",
    "# Extract number of frames\n",
    "num_frames = int(vc.get(cv.CAP_PROP_FRAME_COUNT))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Testing flow values\n",
    "prev_frame_num = num_frames/20\n",
    "curr_frame_num = num_frames/20\n",
    "\n",
    "vc.set(cv.CAP_PROP_POS_FRAMES, curr_frame_num-1)\n",
    "status, frame = vc.read()\n",
    "curr_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "vc.set(cv.CAP_PROP_POS_FRAMES, prev_frame_num-1)\n",
    "status, frame = vc.read()\n",
    "prev_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "vc_tamp.set(cv.CAP_PROP_POS_FRAMES, prev_frame_num-1)\n",
    "status, frame = vc_tamp.read()\n",
    "curr_tamp_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Resize images to 512x512 dimension\n",
    "dim = (512,512)\n",
    "curr_frame = cv.resize(curr_frame, dim, interpolation=cv.INTER_AREA)\n",
    "curr_tamp_frame = cv.resize(curr_tamp_frame, dim, interpolation=cv.INTER_AREA)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate flow\n",
    "flow = cv.calcOpticalFlowFarneback(prev_frame, curr_frame, None, pyr_scale = 0.5, levels = 5, winsize = 11, iterations = 5, poly_n = 5, poly_sigma = 1.1, flags = 0)\n",
    "\n",
    "print(flow[...,0].max(), flow[...,1].max())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "quantized_img = quantize(gaussianHighPass(curr_frame), q=3, t=2)\n",
    "tamp_quant_img = quantize(gaussianHighPass(curr_tamp_frame), q=3, t=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv.imshow('tampered', quantized_img)\n",
    "cv.waitKey(7500)\n",
    "cv.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Get index corresponding to cooccurrence\n",
    "def cooccurrenceIndex(arr):\n",
    "    # print(arr)\n",
    "    return (arr[0]+2)*125 + (arr[1]+2)*25 + (arr[2]+2)*5 + arr[3]+2\n",
    "\n",
    "# Compute co-occurrences\n",
    "def computeRowCooccurrence(img):\n",
    "    cooccurrence = np.zeros((625,), int)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]-3):\n",
    "            cooccurrence[cooccurrenceIndex(img[i][j:j+4])] += 1\n",
    "    return cooccurrence\n",
    "\n",
    "# Compute co-occurrences\n",
    "def computeColCooccurrence(img):\n",
    "    cooccurrence = np.zeros((625,), int)\n",
    "    for i in range(img.shape[0]-3):\n",
    "        for j in range(img.shape[1]):\n",
    "            cooccurrence[cooccurrenceIndex(img[i:i+4,j])] += 1\n",
    "    return cooccurrence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def computeMeanDescriptors(descriptors):\n",
    "    mean = np.zeros((625,), float)\n",
    "    for j in range(625):\n",
    "        mean[j] = (descriptors[0][j] + descriptors[1][j])/2.0\n",
    "    return mean\n",
    "\n",
    "def computeVarianceDescriptors(descriptors):\n",
    "    mean = computeMeanDescriptors(descriptors)\n",
    "    dif1 = descriptors[0]-mean\n",
    "    dif2 = descriptors[1]-mean\n",
    "    variance_sum = np.array([val*val for val in dif1], float).sum() + np.array([val*val for val in dif2], float).sum()\n",
    "    return variance_sum/2.0\n",
    "\n",
    "def computeMahalDist(descriptor, mean, variance):\n",
    "    dif = descriptor-mean\n",
    "    var_sum = np.array([val*val for val in dif], float).sum()\n",
    "    return math.sqrt(var_sum/variance)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Construct heat map\n",
    "heat_map = np.zeros((512, 512), dtype=np.uint8)\n",
    "block_size = (128,128)\n",
    "\n",
    "for row in [block_size[0]*i for i in range(512//block_size[0])]:\n",
    "    for col in [block_size[1]*i for i in range(512//block_size[1])]:\n",
    "        block = quantized_img[row:row+block_size[0], col:col+block_size[1]]\n",
    "        tamp_block = tamp_quant_img[row:row+block_size[0], col:col+block_size[1]]\n",
    "        row_coocc = computeRowCooccurrence(block)\n",
    "        col_coocc = computeColCooccurrence(block)\n",
    "        tamp_row_coocc = computeRowCooccurrence(tamp_block)\n",
    "        tamp_col_coocc = computeColCooccurrence(tamp_block)\n",
    "\n",
    "        mean_desc = computeMeanDescriptors([row_coocc, col_coocc])\n",
    "        variance = computeVarianceDescriptors([row_coocc, col_coocc])\n",
    "        tamp_mean_desc = computeMeanDescriptors([tamp_row_coocc, tamp_col_coocc])\n",
    "\n",
    "        heat_map[row:row+block_size[0],col:col+block_size[1]] = 255-100*computeMahalDist(tamp_mean_desc, mean_desc, variance)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "cv.imshow('Heat map', heat_map)\n",
    "cv.waitKey(7500)\n",
    "cv.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}